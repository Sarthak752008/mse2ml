{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.preprocessing import OneHotEncoder,StandardScaler,LabelEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.metrics import accuracy_score,log_loss\nfrom xgboost import XGBClassifier\ntrain=pd.read_csv(\"/kaggle/input/mle-ese-mock/train (5).csv\")\ntest=pd.read_csv(\"/kaggle/input/mle-ese-mock/test (4).csv\")\ntrain.isnull().sum()\ntest.isnull().sum()\ntest_id=test['id']\ntest=test.drop(columns=['id'])\ntrain=train.dropna(subset=['quality_grade'])\ntrain.isnull().sum()\n\nX=train.drop(columns=['id','quality_grade'])\ny=train['quality_grade']\n\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)\n\nnumeric_features=X.select_dtypes(include=['int64','float64']).columns\ncategorical_features=X.select_dtypes(include=['object']).columns\n\nnumerical_pipeline=Pipeline(steps=[\n    ('imputer',SimpleImputer(strategy='median')),\n    ('scaler',StandardScaler())\n])\ncategorical_pipeline=Pipeline(steps=[\n    ('imputer',SimpleImputer(strategy='most_frequent')),\n    ('encoder',OneHotEncoder(handle_unknown='ignore'))\n])\n\npreprocessing=ColumnTransformer(transformers=[\n    ('num',numerical_pipeline,numeric_features),\n    ('cat',categorical_pipeline,categorical_features)\n])\n\nfrom sklearn.ensemble import HistGradientBoostingClassifier\n\nmodel = HistGradientBoostingClassifier(\n    loss=\"log_loss\",        # IMPORTANT\n    max_iter=100,\n    learning_rate=0.05,\n\n    max_depth=6,\n    min_samples_leaf=30,\n\n    l2_regularization=0.1,\n    max_bins=255,\n\n    random_state=42\n)\n\n\npipeline=Pipeline(steps=[\n    ('preprocessing',preprocessing),\n    ('model',model)\n])\n\nle = LabelEncoder()\ny_train_enc = le.fit_transform(y_train)  # fit on train\ny_test_enc = le.transform(y_test)        # transform test\n\npipeline.fit(X_train,y_train_enc)\n\ny_proba=pipeline.predict_proba(X_test)\n\nloss = log_loss(y_test_enc, y_proba)\nprint(\"Log Loss:\", loss)\n\ny_final=pipeline.predict_proba(test)\n\nclass_names = le.classes_  # use label encoder mapping\nsubmission = pd.DataFrame(y_final, columns=[f\"Status_{cls}\" for cls in class_names])\nsubmission.insert(0, 'id', test_id)\nsubmission.to_csv(\"submission4.csv\", index=False)\nprint(\"\\nâœ… Submission file created successfully!\")\nprint(submission.head())","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}